# -*- coding: utf-8 -*-
"""Spam Ham Email Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gLD_PwMDdgyJRg00_-JkwsdMwegxjGZp

# Importando as dependencias
"""

import os
import re
import math
import copy
import itertools
import collections
import matplotlib.pyplot as plt
import numpy as np

"""# Preparando funções para leitura e armazenamento dos dados"""

# Classe para guardar as instancias de e-mail
class Document:
    text = ""
    word_freqs = {}
    actual_label = ""
    predicted_label = ""

    def __init__(self, text, counter, actual_label):
        self.text = text
        self.word_freqs = counter
        self.actual_label = actual_label

    def getText(self):
        return self.text

    def getWordFreqs(self):
        return self.word_freqs

    def getActualLabel(self):
        return self.actual_label

    def getPredictedLabel(self):
        return self.predicted_label

    def setPredictedLabel(self, guess_label):
        self.predicted_label = guess_label

# função que que identifica a frequência das palavras no texto
def bagOfWords(text):
    bagsofwords = collections.Counter(re.findall(r'\w+', text))
    return dict(bagsofwords)

# função para ler todos os arquivos em um determinado diretório e construir o dataset D
def makeDataSet(storage_dict, directory, actual_label):
    for dir_entry in os.listdir(directory):
        dir_entry_path = os.path.join(directory, dir_entry)
        if os.path.isfile(dir_entry_path):
            with open(dir_entry_path, 'r', encoding="ascii", errors='ignore') as text_file:
                text = text_file.read()
                storage_dict.update({dir_entry_path: Document(text, bagOfWords(text), actual_label)})

# função que cria os datasets de treino e teste a partir dos diretórios dos arquivos
def makeDatasets(training_spam_dir, training_ham_dir, test_spam_dir, test_ham_dir):
    makeDataSet(training_set, training_spam_dir, classes[1])
    makeDataSet(training_set, training_ham_dir, classes[0])
    makeDataSet(test_set, test_spam_dir, classes[1])
    makeDataSet(test_set, test_ham_dir, classes[0])

"""# treinando e testando o algorítmo Multinomial Naive Bayes"""

# função para extrair o vocabulário de um texto em um dataset
def extractVocab(data_set):
    all_text = ""
    v = []
    for x in data_set:
        all_text += data_set[x].getText()
    for y in bagOfWords(all_text):
        v.append(y)
    return v

# função de treino do Naive Bayes
def trainMultinomialNaiveBayes(training, priors, cond):
    v = extractVocab(training)
    n = len(training)
    for c in classes:
        n_c = 0.0
        text_c = ""
        for i in training:
            if training[i].getActualLabel() == c:
                n_c += 1
                text_c += training[i].getText()
        priors[c] = float(n_c) / float(n)
        token_freqs = bagOfWords(text_c)
        # Calculate conditional probabilities for each token and sum using laplace smoothing and log-scale
        for t in v:
            # known word case
            if t in token_freqs:
                cond.update({t + "_" + c: (float((token_freqs[t] + 1.0)) / float((len(text_c) + len(token_freqs))))})
            # unknown word case
            else:
                cond.update({t + "_" + c: (float(1.0) / float((len(text_c) + len(token_freqs))))})


# função de teste 
# retorna a classificação predita
def applyMultinomialNaiveBayes(data_instance, priors, cond):
    score = {}
    for c in classes:
        score[c] = math.log10(float(priors[c]))
        for t in data_instance.getWordFreqs():
            if (t + "_" + c) in cond:
                score[c] += float(math.log10(cond[t + "_" + c]))
    if score["spam"] > score["ham"]:
        return "spam"
    else:
        return "ham"

"""# Plotando a matriz confusão"""

#Evaluation of Model - Confusion Matrix Plot
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix'):
   
    
    plt.figure()
    cmap=plt.cm.Blues
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

"""# Preparando os datasets"""

# Guardando os e-mails em dicionários do tipo: {nome_do_arquivo : e-mail}
training_set = dict()
test_set = dict()
# Definindo as classes para a predição
# ham = 0 para os emails que não são span e spam = 1 para os que são
classes = ["ham", "spam"]

# chama a função que fria os datasets de treino e teste
# os parâmetros são os nomes dos arquivos
makeDatasets('treino/spam', 
             'treino/ham',
             'teste/spam', 
             'teste/ham')

"""# Treinando e testando"""

# Dictionary to store conditional probability and prior
conditional_probability = dict()
prior = dict()

# Train using the training data
trainMultinomialNaiveBayes(training_set, prior, conditional_probability)

# Creating Confusion matrix
# Generating True Positive, False Positive, False Negative, True Negative

true_positives = 0
true_negatives = 0
false_positives = 0
false_negatives = 0    

for i in test_set:
    test_set[i].setPredictedLabel(applyMultinomialNaiveBayes(test_set[i], prior, conditional_probability))
    if test_set[i].getPredictedLabel() == test_set[i].getActualLabel() == "spam":
        true_positives += 1
    elif test_set[i].getPredictedLabel() == test_set[i].getActualLabel() == "ham":
        true_negatives += 1
    elif test_set[i].getPredictedLabel() != test_set[i].getActualLabel() and test_set[i].getPredictedLabel() == "spam":
        false_positives += 1
    else: #test_set[i].getPredictedLabel() != test_set[i].getActualLabel() and test_set[i].getPredictedLabel() == "ham":
        false_negatives += 1

# Computando a métrica
accuracy = float(true_positives+true_negatives) /float(true_positives+true_negatives+false_positives+false_negatives)    # (TP+TN)/(TP+TN+FP+FN)
precision = float(true_positives) /float(true_positives+false_positives)        # (TP)/(TP+FP)
recall = (true_positives) /float(true_positives+false_negatives)                # (TP)/(TP+FN)
f1_score = 2* float((precision*recall) /float(precision+recall))                # 2*(P*R/P+R)

# Exibido a métrica
print ("True positives:", true_positives)
print ("True negatives:", true_negatives)
print ("False positives:", false_positives)
print ("False negatives:", false_negatives)
print ("Total de documentos no conjunto de testes:", len(test_set))
print ("Accuracy:", 100.0*accuracy)
print ("Precision", 100.0*precision)
print ("Recall:", 100.0*recall)
print ("F1-score:", 100.0*f1_score)
cm = np.array([true_negatives, false_positives, false_negatives, true_positives]).reshape(2,2)
plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix')
